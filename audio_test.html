
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
<head>
    <title>Loading and playing a sound with the Web Audio API</title>
    <script type="text/javascript" src="js/jquery.js"></script>
    <script src="js/three.js"></script>
    <style>
        * {
            font-family: sans-serif;
        }
    </style>
 
</head>
<body style="background-color: white;">



<canvas id="canvas" width="1000" height="325" style="display: block;"></canvas>

<script type="text/javascript">

    bg = document.body.style;
    bg.background = '#592b69';

    cubewidth = 150;

      // revolutions per second
      var angularSpeed = 0.1; 
      var lastTime = 0;
 
      // this function is executed on each animation frame
      function animate(){
        // update
        var time = (new Date()).getTime();
        var timeDiff = time - lastTime;
        var angleChange = angularSpeed * timeDiff * 2 * Math.PI / 1000;
        cube.rotation.y += angleChange;
        cube.rotation.x += angleChange;
        cube.rotation.z += angleChange;
        lastTime = time;
 
        // render
        renderer.shadowMapEnabled = true;
        renderer.render(scene, camera);

 
        // request new frame
        requestAnimationFrame(function(){
            animate();
        });
      }

      // renderer
      var renderer = new THREE.WebGLRenderer();
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);
 
      // camera
      var camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 1, 1000);
      camera.position.z = 500;
 
      // scene
      var scene = new THREE.Scene();
                
      // cube
      map = THREE.ImageUtils.loadTexture('images/rose.jpg');
      var cube = new THREE.Mesh(new THREE.CubeGeometry(cubewidth, cubewidth, cubewidth),
      new THREE.MeshBasicMaterial({shading: THREE.FlatShading, color: 0xdcdcdc, map: map}));

      cube.castShadow = true;
      cube.overdraw = true;
      scene.add(cube);



     geometry = new THREE.TorusKnotGeometry(80, 40, 64, 8, 2, 3, 1);

      material = new THREE.MeshNormalMaterial({shading: THREE.FlatShading, transparent: true, opacity: 0.50});
      mesh = new THREE.Mesh(geometry, material);
      scene.add(mesh);

   
 
      // start animation
      animate();

          // create the audio context (chrome only for now)
    var context = new webkitAudioContext();
    var audioBuffer;
    var sourceNode;
    var analyser;
    var javascriptNode;

    // get the context from the canvas to draw on
    var ctx = $("#canvas").get()[0].getContext("2d");

    // create a gradient for the fill. Note the strange
    // offset, since the gradient is calculated based on
    // the canvas, not the specific element we draw
    var gradient = ctx.createLinearGradient(0,0,0,300);
    gradient.addColorStop(1,'#000000');
    gradient.addColorStop(0.75,'#ff0000');
    gradient.addColorStop(0.25,'#ffff00');
    gradient.addColorStop(0,'#ffffff');


    // load the sound
    setupAudioNodes();
    loadSound("audio/song2.mp3");


    function setupAudioNodes() {

        // setup a javascript node
        javascriptNode = context.createJavaScriptNode(2048, 1, 1);
        // connect to destination, else it isn't called
        javascriptNode.connect(context.destination);


        // setup a analyzer
        analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0.3;
        analyser.fftSize = 512;

        // create a buffer source node
        sourceNode = context.createBufferSource();
        sourceNode.connect(analyser);
        analyser.connect(javascriptNode);

        sourceNode.connect(context.destination);
    }

    // load the specified sound
    function loadSound(url) {
        var request = new XMLHttpRequest();
        request.open('GET', url, true);
        request.responseType = 'arraybuffer';

        // When loaded decode the data
        request.onload = function() {

            // decode the data
            context.decodeAudioData(request.response, function(buffer) {
                // when the audio is decoded play the sound
                playSound(buffer);
            }, onError);
        }
        request.send();
    }


    function playSound(buffer) {
        sourceNode.buffer = buffer;
        sourceNode.noteOn(0);
    }

    // log if an error occurs
    function onError(e) {
        console.log(e);
    }

    // when the javascript node is called
    // we use information from the analyzer node
    // to draw the volume
    javascriptNode.onaudioprocess = function() {

        // get the average for the first channel
        var array =  new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);

        // clear the current state
        ctx.clearRect(0, 0, 1000, 325);

        // set the fill style
        ctx.fillStyle=gradient;
        drawSpectrum(array);

    }


    function drawSpectrum(array) {
        for ( var i = 0; i < (array.length); i++ ){
            var value = array[i];

            ctx.fillRect(i*5,325-value,3,325);
            if (i == 1) {
                // cube.rotation.z += value/2000;
                scale = value/200;
                if (scale != 0 ) {
                    //cube.scale.set(scale,scale,scale);
                    

                    mesh.scale.set(scale * .8, scale, 1);

                }
                // cube.scale = value/2000;
                // cube.CubeGeometry.set(value, value, value);
                // cube.material.color.setHex( 0xffffff );
                // cubewidth = value;
                console.log(scale);

            }
            // console.log([i,value])
        }
    };





</script>

</body>
</html>